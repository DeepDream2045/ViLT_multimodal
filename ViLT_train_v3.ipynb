{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1B6YD8HCutsfx-nvNjOZedBQ2Y7MeCslC","timestamp":1692816206402},{"file_id":"1E-9slfd5UR-phvmSfqxfQdfDpTw-0TP_","timestamp":1692805608997}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Preprocess the dataset and stores tensors to Google Driver**"],"metadata":{"id":"V8lmJaG9p8uB"}},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOfTQwxwdb4Z","outputId":"901e9ed3-9de5-4a72-fe3c-2b618ddf1331","executionInfo":{"status":"ok","timestamp":1692830073081,"user_tz":180,"elapsed":2771,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","path = os.path.join('/content/drive/MyDrive/')"]},{"cell_type":"markdown","source":["##**Read data files** ##"],"metadata":{"id":"0VdovDCbCb1M"}},{"cell_type":"markdown","source":["Read dataframes from csv files"],"metadata":{"id":"ruFoadKIqDfz"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"8BB7CBX01v5f","executionInfo":{"status":"ok","timestamp":1692830073082,"user_tz":180,"elapsed":6,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","path = '/content/drive/MyDrive/ViLT'\n","train_file = os.path.join(path, 'combined_train.csv')\n","val_file = os.path.join(path, 'combined_val.csv')\n","test_file = os.path.join(path, 'combined_test.csv')\n","\n","train_df = pd.read_csv(train_file)\n","val_df = pd.read_csv(val_file)\n","test_df = pd.read_csv(test_file)"]},{"cell_type":"markdown","source":["Read train, validation, test data"],"metadata":{"id":"Xggv79drMsU0"}},{"cell_type":"code","source":["# !pip install lightning\n","!pip install transformers"],"metadata":{"id":"Owg-41NW8HP_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692830077432,"user_tz":180,"elapsed":4355,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}},"outputId":"b1050d1c-764f-4d6b-81ee-3dd6e6753d26"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}]},{"cell_type":"markdown","source":["Load pretrained ViLT model"],"metadata":{"id":"2_a5vVPBc46j"}},{"cell_type":"code","source":["from transformers import ViltProcessor, ViltForQuestionAnswering\n","import torch\n","\n","processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n","model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"],"metadata":{"id":"Sg9O4Fc9c87q","executionInfo":{"status":"ok","timestamp":1692830078875,"user_tz":180,"elapsed":1455,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Preprocess the images and comments to encodings and stores them to the storage"],"metadata":{"id":"lu7SwrGqqYsy"}},{"cell_type":"markdown","source":["##**Finetune the ViLT model** ##"],"metadata":{"id":"3oq0moKXcYxu"}},{"cell_type":"markdown","source":["create dataloaders"],"metadata":{"id":"qNXxc2t8HWAm"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset\n","from torchvision.io import read_image\n","from torchvision.transforms import Resize\n","import torchvision\n","import numpy as np\n","\n","class ViltDataset(Dataset):\n","  def __init__(self, dataframes):\n","    self.base_path = '/content/drive/MyDrive/ViLT'\n","    self.img_paths = dataframes['filename']\n","    self.comments = dataframes['clean_comments']\n","    self.resize = Resize((384, 512))\n","    self.labels = dataframes['scenic']\n","\n","  def __len__(self):\n","    return len(self.img_paths)\n","\n","  def __getitem__(self, idx):\n","    img_path = self.img_paths[idx]\n","    img = self.resize(read_image(os.path.join(self.base_path, img_path), mode=torchvision.io.ImageReadMode.RGB))\n","    comment = self.comments[idx]\n","    encoding = processor(img, comment, return_tensors='pt', padding='max_length', truncation=True)\n","    label = torch.nn.functional.one_hot(torch.tensor(self.labels[idx]), num_classes=2)\n","\n","    return [encoding, label]"],"metadata":{"id":"WhkwNJb2Mq9I","executionInfo":{"status":"ok","timestamp":1692830078876,"user_tz":180,"elapsed":10,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# create dataloaders\n","training_data = ViltDataset(train_df[:])\n","test_data = ViltDataset(test_df[:])\n","val_data = ViltDataset(val_df[:])"],"metadata":{"id":"omv-m-oZCJRS","executionInfo":{"status":"ok","timestamp":1692830078876,"user_tz":180,"elapsed":9,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=10, shuffle=True)\n","val_dataloader = DataLoader(val_data, batch_size=10, shuffle=True)"],"metadata":{"id":"U-2KK3Iq8zl6","executionInfo":{"status":"ok","timestamp":1692830078877,"user_tz":180,"elapsed":10,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Define a classifier model"],"metadata":{"id":"5uFd3ks9pJ1-"}},{"cell_type":"code","source":["class ScenicClassifier(torch.nn.Module):\n","  def __init__(self, enc_features: int):\n","    super().__init__()\n","    self.embedding = model.vilt\n","    self.classifier = torch.nn.Sequential(\n","        torch.nn.Linear(enc_features, 64, bias=False),\n","        # torch.nn.ReLU(),\n","        torch.nn.Linear(64, 16, bias=False),\n","        torch.nn.Linear(16, 2, bias=False),\n","        # torch.nn.ReLU()\n","        )\n","\n","  def forward(self, encodings):\n","    embeds = self.embedding(**encodings)['pooler_output']\n","    logits = self.classifier(embeds)\n","\n","    return logits"],"metadata":{"id":"fCursQRDpuQt","executionInfo":{"status":"ok","timestamp":1692836639089,"user_tz":180,"elapsed":350,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["class ScenicClassifier2(torch.nn.Module):\n","  def __init__(self, enc_features: int):\n","    super().__init__()\n","    self.embedding = model.vilt\n","    self.classifier = torch.nn.Linear(enc_features, 2, bias=False)\n","    torch.nn.init.xavier_uniform(self.classifier.weight)\n","\n","  def forward(self, encodings):\n","    embeds = self.embedding(**encodings)['pooler_output']\n","    logits = self.classifier(embeds)\n","\n","    return logits"],"metadata":{"id":"rGBmqrnSCIay","executionInfo":{"status":"ok","timestamp":1692830078877,"user_tz":180,"elapsed":9,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["device='cuda:0'\n","# device='cpu'\n","classifier = ScenicClassifier(768)\n","# classifier = ScenicClassifier2(768)\n","classifier.to(device)\n","\n","criterion = torch.nn.MSELoss()\n","criterion.to(device)\n","# optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n","optimizer = torch.optim.SGD(classifier.parameters(), lr=0.0001, momentum=0.8)"],"metadata":{"id":"X2BZaJoUr34u","executionInfo":{"status":"ok","timestamp":1692836642693,"user_tz":180,"elapsed":344,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"Aiqeg0CCshG2"}},{"cell_type":"code","source":["classifier.train()\n","for epoch in range(4):\n","  running_loss = 0.0\n","  for i, data in enumerate(train_dataloader, 0):\n","    encodings, labels = data\n","    encodings.to(device)\n","    labels.to(device)\n","    for key in encodings.keys():\n","      encodings[key] = torch.squeeze(encodings[key], 1)\n","    optimizer.zero_grad()\n","    outputs = classifier(encodings)\n","    labels = torch.tensor(labels, dtype=torch.float).cuda()\n","    # new_labels = []\n","    # for label in labels:\n","    #   new_labels.append(torch.nn.functional.one_hot(torch.squeeze(torch.tensor(label, dtype=torch.int)), num_classes=2))\n","    # new_labels = torch.tensor(new_labels)\n","\n","    # print(outputs)\n","    # print(new_labels)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    running_loss += loss.item()\n","    if i % 10 == 9:\n","      print(f'[{epoch+1}, {i+1:5d}] loss : {running_loss / 10:.3f}')\n","      running_loss=0.0\n","\n","print('Finished training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wN-Fr0bSstyT","executionInfo":{"status":"ok","timestamp":1692839050320,"user_tz":180,"elapsed":2401741,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}},"outputId":"184e5ffc-adca-4978-a1c6-01513527721e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-39-0642d53086cb>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(labels, dtype=torch.float).cuda()\n"]},{"output_type":"stream","name":"stdout","text":["[1,    10] loss : 0.497\n","[1,    20] loss : 0.417\n","[1,    30] loss : 0.365\n","[1,    40] loss : 0.297\n","[1,    50] loss : 0.255\n","[1,    60] loss : 0.217\n","[1,    70] loss : 0.188\n","[1,    80] loss : 0.163\n","[1,    90] loss : 0.144\n","[1,   100] loss : 0.128\n","[1,   110] loss : 0.111\n","[1,   120] loss : 0.102\n","[1,   130] loss : 0.092\n","[1,   140] loss : 0.087\n","[1,   150] loss : 0.093\n","[1,   160] loss : 0.088\n","[1,   170] loss : 0.083\n","[1,   180] loss : 0.085\n","[1,   190] loss : 0.092\n","[1,   200] loss : 0.079\n","[1,   210] loss : 0.072\n","[1,   220] loss : 0.075\n","[1,   230] loss : 0.089\n","[1,   240] loss : 0.086\n","[1,   250] loss : 0.086\n","[2,    10] loss : 0.072\n","[2,    20] loss : 0.067\n","[2,    30] loss : 0.077\n","[2,    40] loss : 0.084\n","[2,    50] loss : 0.067\n","[2,    60] loss : 0.079\n","[2,    70] loss : 0.073\n","[2,    80] loss : 0.070\n","[2,    90] loss : 0.075\n","[2,   100] loss : 0.065\n","[2,   110] loss : 0.076\n","[2,   120] loss : 0.079\n","[2,   130] loss : 0.064\n","[2,   140] loss : 0.079\n","[2,   150] loss : 0.074\n","[2,   160] loss : 0.069\n","[2,   170] loss : 0.060\n","[2,   180] loss : 0.076\n","[2,   190] loss : 0.069\n","[2,   200] loss : 0.079\n","[2,   210] loss : 0.086\n","[2,   220] loss : 0.075\n","[2,   230] loss : 0.073\n","[2,   240] loss : 0.088\n","[2,   250] loss : 0.081\n","[3,    10] loss : 0.073\n","[3,    20] loss : 0.072\n","[3,    30] loss : 0.067\n","[3,    40] loss : 0.076\n","[3,    50] loss : 0.078\n","[3,    60] loss : 0.078\n","[3,    70] loss : 0.070\n","[3,    80] loss : 0.069\n","[3,    90] loss : 0.073\n","[3,   100] loss : 0.079\n","[3,   110] loss : 0.061\n","[3,   120] loss : 0.061\n","[3,   130] loss : 0.083\n","[3,   140] loss : 0.063\n","[3,   150] loss : 0.075\n","[3,   160] loss : 0.077\n","[3,   170] loss : 0.064\n","[3,   180] loss : 0.062\n","[3,   190] loss : 0.073\n","[3,   200] loss : 0.072\n","[3,   210] loss : 0.059\n","[3,   220] loss : 0.072\n","[3,   230] loss : 0.072\n","[3,   240] loss : 0.072\n","[3,   250] loss : 0.085\n","[4,    10] loss : 0.088\n","[4,    20] loss : 0.063\n","[4,    30] loss : 0.075\n","[4,    40] loss : 0.066\n","[4,    50] loss : 0.076\n","[4,    60] loss : 0.067\n","[4,    70] loss : 0.064\n","[4,    80] loss : 0.081\n","[4,    90] loss : 0.070\n","[4,   100] loss : 0.072\n","[4,   110] loss : 0.064\n","[4,   120] loss : 0.062\n","[4,   130] loss : 0.065\n","[4,   140] loss : 0.070\n","[4,   150] loss : 0.063\n","[4,   160] loss : 0.071\n","[4,   170] loss : 0.084\n","[4,   180] loss : 0.078\n","[4,   190] loss : 0.057\n","[4,   200] loss : 0.072\n","[4,   210] loss : 0.060\n","[4,   220] loss : 0.068\n","[4,   230] loss : 0.059\n","[4,   240] loss : 0.065\n","[4,   250] loss : 0.077\n","Finished training\n"]}]},{"cell_type":"markdown","source":["## Test the result"],"metadata":{"id":"Ent3CC_jDDSO"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def f1_score_eval(dataloader, dataname):\n","  correct = 0\n","  total = 0\n","  predicts = []\n","  groundtruth = []\n","  with torch.no_grad():\n","    for testdata in dataloader:\n","      encodings, labels = testdata\n","      encodings = encodings.to(device)\n","      for key in encodings.keys():\n","        encodings[key] = torch.squeeze(encodings[key], 1)\n","      output = classifier(encodings)\n","      _, predicted = torch.max(output.data, 1)\n","      predicts.append(predicted.to('cpu'))\n","      total+= labels.size(0)\n","      groundtruth.append(torch.argmax(labels.to('cpu'), 1))\n","      correct+=(predicted.to('cpu')==torch.argmax(labels.to('cpu'), 1)).sum().item()\n","\n","  print(f'Accuracy of the network on {dataname} images : {100*correct//total}%')\n","  print(predicts)\n","  print(groundtruth)\n","  f1 = f1_score(np.asarray(predicts), np.asarray(groundtruth))\n","  print(f'F1 Score of the network on {dataname} images: {f1 * 100}%')"],"metadata":{"id":"_7MbXtVjCCFB","executionInfo":{"status":"ok","timestamp":1692841448258,"user_tz":180,"elapsed":5,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["f1_score_eval(val_dataloader, 'validation')\n","f1_score_eval(test_dataloader, 'test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"FRGf-T0xCpUf","executionInfo":{"status":"error","timestamp":1692841503589,"user_tz":180,"elapsed":44642,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}},"outputId":"a3dea274-d0b3-446b-f7ea-63aeb4e09cd1"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of the network on validation images : 91%\n","[tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0]), tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 0]), tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 0]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1]), tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1]), tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0]), tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0]), tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1]), tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 1]), tensor([0, 1, 1, 1, 0, 1, 1, 0, 1, 1]), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 1]), tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1]), tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0]), tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 1]), tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 0]), tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 1]), tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 1]), tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 0]), tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1]), tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0]), tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0]), tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1]), tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1]), tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0]), tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1]), tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 1]), tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0]), tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 1]), tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 0]), tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 0]), tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 1]), tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0]), tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0]), tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 1]), tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1]), tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1]), tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1]), tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1]), tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 0]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 0]), tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0]), tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1]), tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 1]), tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0]), tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 1]), tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0]), tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 1]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0]), tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0]), tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 0]), tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0]), tensor([0, 0, 1, 1, 1, 1, 1, 0, 0, 0]), tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0]), tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0]), tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1]), tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 0]), tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0]), tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 1]), tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0]), tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1]), tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 0]), tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 0]), tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 1]), tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 0]), tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1]), tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 1]), tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0]), tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 0]), tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 1]), tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 1]), tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1]), tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0]), tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 0]), tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1])]\n","[tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0]), tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1]), tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 0]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0]), tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1]), tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 1]), tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 0]), tensor([0, 1, 1, 1, 1, 0, 0, 1, 0, 0]), tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1]), tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 1]), tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1]), tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1]), tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 1]), tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1]), tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0]), tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 1]), tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 0]), tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 1]), tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1]), tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1]), tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 1]), tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 0]), tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1]), tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1]), tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0]), tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1]), tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0]), tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0]), tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1]), tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1]), tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0]), tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 1]), tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 0]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0]), tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1]), tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 1]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 1]), tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1]), tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1]), tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1]), tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1]), tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 0]), tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0]), tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0]), tensor([0, 1, 0, 1, 0, 0, 0, 1, 0, 1]), tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 1]), tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0]), tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1]), tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0]), tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 0]), tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0]), tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0]), tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 0]), tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 1]), tensor([0, 0, 1, 1, 1, 1, 1, 0, 0, 0]), tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0]), tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1]), tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 1]), tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0]), tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0]), tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 1]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 0]), tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1]), tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0]), tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0]), tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 1]), tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 0]), tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1]), tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1]), tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0]), tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1]), tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 1]), tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1]), tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1]), tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0]), tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 0]), tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1])]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-6eba3a0c4e2a>:24: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  f1 = f1_score(np.asarray(predicts), np.asarray(groundtruth))\n","<ipython-input-52-6eba3a0c4e2a>:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  f1 = f1_score(np.asarray(predicts), np.asarray(groundtruth))\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-f4f68e80f007>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf1_score_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-6eba3a0c4e2a>\u001b[0m in \u001b[0;36mf1_score_eval\u001b[0;34m(dataloader, dataname)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'F1 Score of the network on {dataname} images: {f1 * 100}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unknown is not supported"]}]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","predicts = []\n","groundtruth = []\n","with torch.no_grad():\n","  for testdata in val_dataloader:\n","    encodings, labels = testdata\n","    encodings = encodings.to(device)\n","    for key in encodings.keys():\n","      encodings[key] = torch.squeeze(encodings[key], 1)\n","    output = classifier(encodings)\n","    _, predicted = torch.max(output.data, 1)\n","    predicts.append(predicted)\n","    total+= labels.size(0)\n","    # print(predicted)\n","    # print(labels)\n","    # print(torch.argmax(labels, 1))\n","    # break\n","    groundtruth.append(labels.to('cpu'), 1))\n","    correct+=(predicted.to('cpu')==torch.argmax(labels.to('cpu'), 1)).sum().item()\n","\n","print(f'Accuracy of the network : {100*correct//total}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_6BL7Y2DG7r","executionInfo":{"status":"ok","timestamp":1692836495604,"user_tz":180,"elapsed":45738,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}},"outputId":"7accb919-2bba-481f-ec60-cda74bc65bcb"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of the network : 91%\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","f1 = f1_score(np.asarray(predicts), np.asarray(groundtruth), average='binary')\n","print(f'F1 Score of the network on validation images: {f1 * 100}%')"],"metadata":{"id":"DRIhTpKm8Sls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","!nvidia-smi -caa\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spZNhcF-1V8o","executionInfo":{"status":"ok","timestamp":1692836540992,"user_tz":180,"elapsed":495,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}},"outputId":"377236c3-7155-47cf-cf55-5a2b0cac46bd"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleared Accounted PIDs for GPU 00000000:00:04.0.\n","All done.\n","Thu Aug 24 00:22:36 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    36W /  70W |   2093MiB / 15360MiB |     68%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["\n","\n","### TRASH BELOW ###\n","\n"],"metadata":{"id":"0rXzO2Pr0ChV"}},{"cell_type":"code","source":["# text_embeds = model.vilt.embeddings.text_embeddings(encoding['input_ids'])\n","# print(encoding['input_ids'])\n","# encoding = encoding['input_ids', 'token_type_ids', 'pixel_values', 'pixel_mask']\n","\n","# output = model(**encoding)\n","# print(output)\n","# text_emb = model.vilt.embeddings.text_embeddings(**encoding)\n","# print(output.keys())"],"metadata":{"id":"E_-LTpS6fRVS","executionInfo":{"status":"aborted","timestamp":1692833241384,"user_tz":180,"elapsed":25,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# img_embedding = processor.image_processor(image)\n","# print(img_embedding)\n","# encoding = processor(image, text, return_tensors='pt')\n","# print(encoding.keys())"],"metadata":{"id":"I9zayEVyHrtY","executionInfo":{"status":"aborted","timestamp":1692833241385,"user_tz":180,"elapsed":26,"user":{"displayName":"Vieira Santos","userId":"08068415631794455751"}}},"execution_count":null,"outputs":[]}]}